什么是resnet？
#resnet
ResNet（残差网络）的核心思想是通过引入跳跃连接（shortcut connection）或称为残差连接（residual connection）来解决深度神经
网络中的梯度消失和梯度爆炸问题。

在传统的深度神经网络中，信息会从输入层逐层向前传播到输出层。这意味着在反向传播过程中，梯度通过每一层的权重更新回到较早的层。然而，在
非常深的网络中，梯度可能会因为经过多次连续的非线性变换而变得非常小（梯度消失问题）或非常打（梯度爆炸问题），导致网络无法进行有效的学习。

为了解决这个问题，ResNet引入残差（residual block）。一个残差由两个卷积层组成，其中第二卷积层的输出与输入直接相加。这个跳跃允许连接输入数据绕过
卷积层直接传递给输出层，构成一个残差路径。如果输入和输出不匹配，可以通过额外的1*1卷积层调整维度。

通过残差块的跳跃连接，梯度可以更容易地传回。如果前向传播过程中某个卷积层对输入的变换时恒等映射（即输出等于输入），那么反向传播时，梯度可以通过
跳跃直接连接传递到较早的层，避免了梯度消失或梯度爆炸。

ResNet还引入了"残差学习"的概念，即学习残差而不是学习完整的映射。这种方式可以更容易地优化网络，因为只需要学习相对于恒等映射的
残差部分。
