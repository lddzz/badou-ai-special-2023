AlexNet是一个由多个卷积层喝全连接层组成得深度神经网络模型。
1.输入层
AlexNet的输入层接受图像数据作为输入，图像通常为RGB格式，并且被调整为固定的尺寸。

2.卷积层1：
AlexNet的第一卷积层包含96个卷积核，每个卷积核的大小11*11*3（宽*高*通道数），步长为4，并使用ReLU激活函数。这一层的作用是提取输入图像的低级特征。

3.池化层1：
在卷积层1后面是一个最大池化层，窗口大小为3*3，步长为2。这一层的作用是对特征进行下采样，减少数据大小，同时保留主要信息。

4.卷积层2
AlexNet的第二个卷积层有256个卷积核，每个大小为5*5*48（宽*高*通道数），步长为1，并使用ReLU激活函数。这一层进一步提取图像的特征。

5.池化层2
类似于池化层1，池化层2对卷积层2的特征进行下采样，窗口大小为3*3，步长为2.

6.卷积层3--5
AlexNet的第三，四，五卷积层都是384个3*3卷积核，并且使用ReLU激活函数。这些卷积层用于进一步提取图像的高级特征。

7，池化层3：
池化层3的窗口大小为3*3，步长为2，继续对特征进行下采样。

8.全连接层1：
在池化层3之后是三个全连接层。第一个全连接层有4096个神经元，并且使用ReLU激活函数。这一层的作用是将卷积层提取的特征映射到
更高维的空间中。

9.Dropout层1：
为了减少过拟合，全连接层1后面添加了一个Dropout层，随机丢弃部分神经元的输出。

10.全连接层2：
第二个全连接层也有4096个神经元，并且使用ReLU激活函数。

11.Dropout层2：
类似于Dropout层1，为了进一步减少过拟合，全连接层2后加入一个Dropout层。

12.输出层：
输出层是一个具有1000个神经元的全连接层，对应ImageNet数据集中的1000个类别。

卷积层和池化层以及全连接层和Dropout层有什么不同？
功能：
卷积层：卷积层通过卷积操作从输入数据中提取局部特征，并保留了输入数据的空间信息。它在图像识别等任务中表现良好。
池化层：池化层主要用于减小特征图的空间尺寸，减少计算量，并且能够保留主要特征。最常见的池化操作是最大池化和平均池化和平均池化。
全连接层：全连接层将前一次层的所有神经元相连，用于对特征进行整体组合和分类，常用于输出层。
Dropout层：Dropout层是一种正则化技术，用于随机地将一定比例的神经元输出置为零，以减少的过拟合现象。
参数共享：
卷积层：卷积层具有参数共享的特点，即卷积核的权重在整个输入上共享。这样可以减少参数数量，提高模型的效率。
池化层：池化层没有可学习的参数，它仅进行固定的聚合操作来减小特征图的尺寸。
输入数据形状：
卷积层和池化层：通常用于处理具有空间结构的输入数据，例如图像数据，其中数据可以被视为二维或三维张量
全连接层和Dropout层：可以接收任意形状的输入数据，将输入数据展平为一维向量。
权重更新：
卷积层和全连接层：卷积层和全连接层都具有可学习的权重，其更新通过反向传播和优化算法（如梯度下降）进行。
Dropout层：Dropout层没有权重，而是根据指定的概率随机丢弃神经元的输出，因此不需要进行权重更新。

在结构上：
1.卷积层
卷积层由一组可学习的卷积核（filter）组成。每个卷积核对输入数据进行卷积操作，通过逐元素相乘和累加的方式提取局部特征。
卷积层通常包括多个卷积核，每个卷积核用于检测不同的特征。
卷积层具有权重共享的特点，即不同位置的相同特征使用相同的参数，这样减少了参数数量并提高了模型的效率。
输出特征图的维度由卷积操作的步幅，填充方式和卷积核的尺寸决定。
2.池化层（Pooling Layer）：
池化层主要用于减小哦特征图的空间尺寸，减少计算量，并且能够保留主要特征。
最常见的池化操作时最大池化和平均池化
池化层通常不具有可学习的参数，它将输入特征图的局部区域进行聚合操作，例如取最大值或平均值。
池化操作通过指定的池化大小和步幅来控制输出特征图的尺寸。
3.全连接层
全连接仓将钱一层的所有神经元与当前层的每个神经元相连，用于对特征进行整体组合和分类。
全连接层具有可学习的权重和偏置，可以通过反向传播和优化算法进行权重更新。
输入数据通常被展平称为一维向量，作为全连接层的输入。
4.Dropout层：
Dropout层是一种正则化技术，用于减少模型的过拟合现象。
Dropout层随机地将一定比例的神经元输出置为零，即丢失这些神经元的激活值。
Dropout层在训练过程中起到随机失活的效果，可以减少神经元之间的依赖关系，提高模型的泛化能力。
在测试阶段，不应用Dropout层，而是将所有神经元的输出乘以保留率，以保持期望的总体输出。


